

1 mark: properly formatted README file

2 marks: instructions to reproduce/replicate results

2 marks: data availability

5 marks: result replication/reproduction


# **CMPUT 416/500 - Machine Learning Methods in Detecting SQL Injection Vulnerability**

| Team Member | Contact           |
|-------------|-------------------|
| Eden Zhou   | zhou9@ualberta.ca |
|             |                   |
|             |                   |

- [Part 1 - Project Overview](#part-1---project-overview)
- [Part 2 - Data Availability](#part-2---data-availability)
  * [2.1 Data Input](#21-data-input)
    + [2.1.1 Data Preprocessing](#211-data-preprocessing)
    + [2.1.2 Data Embedding](#212-data-embedding)
    + [2.1.3 Data Splitting](#213-data-splitting)
  * [2.2 Data Output](#22-data-output)
    + [2.2.1 Prediction Outcomes](#221-prediction-outcomes)
    + [2.2.2 Diagram Saving](#222-diagram-saving)
  * [2.3 Data Structures](#23-data-structures)
  * [2.4 Data Analysis](#24-data-analysis)
- [Part 3 - Program Execution](#part-3---program-execution)
  * [3.1 Environment Setup](#31-environment-setup)
    + [3.1.1 Compiling Environment](#311-compiling-environment)
    + [3.1.2 Extension Dependency](#312-extension-dependency)
  * [3.2 Replication Instruction](#32-replication-instruction)
    + [3.2.1 Command-based Execution](#321-command-based-execution)
    + [3.2.2 Script-based Execution](#322-script-based-execution)
- [Part 4 - Learning Designs](#part-4---learning-designs)
  * [4.1 Model Construction](#41-model-construction)
    + [4.1.1 Machine Learning Models](#411-machine-learning-models)
    + [4.1.2 Deep Learning Models](#412-deep-learning-models)
  * [4.2 Learning Patterns](#42-learning-patterns)
  * [4.3 Storing and Reloading](#43-storing-and-reloading)
    + [4.3.1 Model Storing](#431-model-storing)
    + [4.3.2 Model Reloading](#432-model-reloading)
    + [4.3.3 Model Re-training](#433-model-re-training)
  * [4.4 Benchmarks and Analysis](#44-benchmarks-and-analysis)
- [Part 5 - Performance Comparisons](#part-5---performance-comparisons)
  * [5.1 Word2Vec-based Model Outcomes](#51-word2vec-based-model-outcomes)
  * [5.2 BoW-based Model Outcomes](#52-bow-based-model-outcomes)
- [Part 6 - Error Handling](#part-6---error-handling)
- [Part 7 - References](#part-7---references)
  * [7.1 Reusing Claim](#71-reusing-claim)
  * [7.2 External Reference](#72-external-reference)


# Part 1 - Project Overview
> 
> ...


# Part 2 - Data Availability
## 2.1 Data Input
- By default, the program assumes the input training data files presented in the `/data` directory of the program package;
- And the original data should be stored in a file in the format of `.json`;
- Users may define their own input path (for training) by changing **the first bracket part** of the training command;
- Users may define their own input path (for test) by changing **the second bracket part** of the prediction command;

### 2.1.1 Data Preprocessing
### 2.1.2 Data Embedding
### 2.1.3 Data Splitting

## 2.2 Data Output
- Commonly, all the model data learned from model training will be stored in `.tsv` files in the program package;
  - Each TSV file contains data from an original JSON file, and it has **three** columns created: 
    - `type`, the type of the dataline, as "centroid" or "idf";
    - `category/term`, the category type if type="centroid" / the term in string if type="idf";
    - `categoryCentroid/termIDF`, category centroid represent in string (for each token and value) if type="centroid" / the token idf value if type="idf";
- Users may define their own output path by changing **the second bracket part** of the training command;
- Commonly, the file created in training will be used for model test in prediction, defined by **the first bracket part** of the prediction command;
### 2.2.1 Prediction Outcomes
### 2.2.2 Diagram Saving

## 2.3 Data Structures
- Raw data structure after JSON loading: a list contains multiple dictionaries, and each dictionary holds keys of doc, and text, each doc is considered as a data sample:
  - **Raw Input** >> List of dicts, \[{category_1:"XXX", text_1:"XX XX XXX""}, {category_2:"XXX", text_2:"XX XX XXX""}, ...]


- Rearranged training data structure: we assign each doc sample with and docID, this can be used as the key to take out the relevant data:
  - **Training/Test Data** >> Dict of nested-lists, {docID_1: \[docCategory_1, \[token_1_1, token_1_2, ...], docID_2:\[docCategory_2, \[token_2_1, token_2_2, ...]], ...}


- The model probability data structures for dara learned in training:
  - **Category Centroid** >> Nested-dicts, {category_1: {token_1_1:tokenWeight_1_1, token_1_2:tokenWeight_1_2, ...}, category_2: {token_2_1:tokenWeight_2_1, ...}, ...}
  - **Token IDF** >> Hashtable, {token_1:tokenIDF_1, token_2:0.tokenIDF_2, ...}


- The model predictions for each sample doc will be recorded as:
  - **Doc Prediction** >> Dict, {testDocId_1:"category", testDocId_2:"category", ...}


- Distance recording and ranking data structures:
  - **Distance Recorder** >> Dict, {category_1:distToTestDocInInt_1, category_2:distToTestDocInInt_2, ...}
  - **Distance Ranker** >> MinHeap, \[(distToTestDocInInt_1, categoryCentroid_1), (distToTestDocInInt_2, categoryCentroid_2), ...]


## 2.4 Data Analysis
- The model prediction contains a method called self.modelAnalyze which will be call automatically to evaluate the model predictions;
- Analysis results needed will be printed to `STDOUT` channel:
  - Class-level: `true positive`, `false positive`, `false negative`, `true negative`;
  - Class-level: `precision`, `recall` and `F1 scores`;
  - Overall: `micro-averaged F1` & `macro-averaged F1` for the entire test set;


# Part 3 - Program Execution
## 3.1 Environment Setup
### 3.1.1 Compiling Environment
- A properly built **Python environment** is mandatory for executing both programs
  
   - **Original Development Environment**: `Python 3.10`;

### 3.1.2 Extension Dependency
- with the following **libraries** required under the environment:

   - **Environmental Built-in Libraries**: `sys`, `os`;
  
         * Libraries above should be pre-installed in a standard python environment *
   
  - **Third-party Processing Libraries**: `gensim`, `sklearn`, `numpy`, `nltk`, and `tqdm`;

        * Please refer to file "./requirements.txt" for automatic extension setup *

## 3.2 Replication Instruction
### 3.2.1 Command-based Execution 
(for New Models)
> or using execution commands...
>
(for Pre-trained Models)
> or using execution commands...
>

### 3.2.2 Script-based Execution 
(for New Models)
> a `Shell` program is prepared to process the execution...

(for Pre-trained Models)
> a `Shell` program is prepared to process the execution...



# Part 4 - Learning Designs

## 4.1 Model Construction
### 4.1.1 Machine Learning Models
- logistic reg
- knn
- svm
- nbs
- rocchio
- ### 4.1.2 Deep Learning Models
- RNN
- LSTM

## 4.2 Learning Patterns
- Cross validation
- train-valid-predict ratio
- Minibatch GD
- loop over hyperparamters

## 4.3 Storing and Reloading
### 4.3.1 Model Storing
### 4.3.2 Model Reloading
### 4.3.3 Model Re-training

## 4.4 Benchmarks and Analysis



# Part 5 - Performance Comparisons
## 5.1 Word2Vec-based Model Outcomes
|                        | [Logistic Regression]() | [k-Nearest Neighbors]() | [Rocchio]() | [Naive Bayes]() | [Support Vector Machine]() | 
|------------------------|-------------------------|-------------------------|-------------|-----------------|----------------------------|
| TP                     |                         |                         |             |                 |                            |                         
| FP                     |                         |                         |             |                 |                            |                         
| TN                     |                         |                         |             |                 |                            |                         
| FN                     |                         |                         |             |                 |                            |                         
| Accuracy               |                         |                         |             |                 |                            |                         
| F1_micro               |                         |                         |             |                 |                            |                         
| F1_macro               |                         |                         |             |                 |                            |                         
| Test Loss              |                         |                         |             |                 |                            |                         
| Optimal Hyperparameter |                         |                         |             |                 |                            |                         

|                        | [Fully-Connected NNs]() | [Recurrent NNs]() | [Long Short-term Memory NNs]() |
|------------------------|-------------------------|-------------------|--------------------------------|
| TP                     |                         |                   |                                |                    
| FP                     |                         |                   |                                |                        
| TN                     |                         |                   |                                |                           
| FN                     |                         |                   |                                |                      
| Accuracy               |                         |                   |                                |
| F1_micro               |                         |                   |                                |                   
| F1_macro               |                         |                   |                                |                     
| Test Loss              |                         |                   |                                |                          
| Optimal Hyperparameter |                         |                   |                                |                        

## 5.2 BoW-based Model Outcomes
|                        | [Logistic Regression]() | [k-Nearest Neighbors]() | [Rocchio]() | [Naive Bayes]() | [Support Vector Machine]() | 
|------------------------|-------------------------|-------------------------|-------------|-----------------|----------------------------|
| TP                     |                         |                         |             |                 |                            |                         
| FP                     |                         |                         |             |                 |                            |                         
| TN                     |                         |                         |             |                 |                            |                         
| FN                     |                         |                         |             |                 |                            |                         
| Accuracy               |                         |                         |             |                 |                            |                         
| F1_micro               |                         |                         |             |                 |                            |                         
| F1_macro               |                         |                         |             |                 |                            |                         
| Test Loss              |                         |                         |             |                 |                            |                         
| Optimal Hyperparameter |                         |                         |             |                 |                            |                         

|                        | [Fully-Connected NNs]() | [Recurrent NNs]() | [Long Short-term Memory NNs]() |
|------------------------|-------------------------|-------------------|--------------------------------|
| TP                     |                         |                   |                                |                    
| FP                     |                         |                   |                                |                        
| TN                     |                         |                   |                                |                           
| FN                     |                         |                   |                                |                      
| Accuracy               |                         |                   |                                |
| F1_micro               |                         |                   |                                |                   
| F1_macro               |                         |                   |                                |                     
| Test Loss              |                         |                   |                                |                          
| Optimal Hyperparameter |                         |                   |                                |                        


# Part 6 - Error Handling

# Part 7 - References

## 7.1 Reusing Claim
> * The primary parts of Training and Prediction in the `NBC model` are edited and reused;
> 
> * The model was taken from `NaiveBayesModel` constructed for `CMPUT 497/501: Intro to NLP` in Fall 22;
> 
> * Original authors who constructed the model: `Eden Zhou (Edennnnnnnnnn)` and `Menghan Chen (menghan-cmh)`, with original link to [GitHub Repo](https://github.com/UOFA-INTRO-NLP-F21/f2021-asn5-Edennnnnnnnnn);

## 7.2 External Reference
> About NLTK Methods:
> - https://www.nltk.org/



# ------------------------------------------------------------
# Program Architecture

## Model 01 - Naive Bayes (NBs) Classifier

### Algorithms & Logics
#### Training
> This implementation provides a framework for training a Laplace-smoothed (aka. add-one smoothing) Naive Bayes classifier on text data. The modelInput method preprocesses the training data by calling the dataFilter method to remove stopwords and punctuation marks from the text. 
> It then stores the category and preprocessed text in a hash table. The modelTrain method trains the Naive Bayes classifier model by counting the occurrences of words in each category and storing the prior probabilities and likelihoods of each word in a dictionary.

#### Prediction
> The Naive Bayes algorithm used in this implementation works by computing the probabilities of each category given a new input document, based on the prior probabilities and the likelihoods of each word in the test documents. The modelInput method preprocesses the training data by calling the dataFilter method to remove stopwords and punctuation marks. It assumes that each word in the document is independent of each other, which is why it is called "naive".
> The algorithm computes the log of the probabilities instead of the probabilities themselves to avoid numerical underflow issues that can occur when multiplying many small probabilities together. The log of the probabilities can be added instead of multiplied, which is more computationally efficient and avoids underflow issues.


### Execution Commands
#### Training
* To run `nbc_train.py` for training NBs models, using the command shown below:
 
  `python3 ./nbc/nbc_train.py [inputTrainingDataFilePath.json] [outputModelDataFilePath.tsv]`

  * The first bracket part in the bracket is related to a `.json` file that contains all training data; 
  * The second bracket defines the model output file, which should be a `.tsv` file;
 
* A Formal sample command that could be used under the program directory is:

  `python3 ./nbc/nbc_train.py ./data/train.json ./nbc_bbc_model.tsv`

#### Prediction
* To run `nbc_prediction.py` for prediction on NBs models, using the command shown below:
  
  `python3 ./nbc/nbc_prediction.py [outputModelDataFilePath.tsv] [inputTestDataFilePath.json]`

  * The first bracket part is related to a `.tsv` file that contains all model data learned; 
  * The second bracket part is related to a `.json` file that contains all test data; 

* A Formal sample command that could be used under the program directory is:

  `python3 ./nbc/nbc_prediction.py ./nbc_bbc_model.tsv ./data/test.json`

### Data Input
- By default, the program assumes the input training data files presented in the `/data` directory of the program package;
- And the original data should be stored in a file in the format of `.json`;
- Users may define their own input path (for training) by changing **the first bracket part** of the training command;
- Users may define their own input path (for test) by changing **the second bracket part** of the prediction command;

### Data Output
- Commonly, all the model data learned from model training will be stored in `.tsv` files in the program package;
  - Each TSV file contains data from an original JSON file, and it has **four** columns created: 
    - `type`, the type of the dataline, as "prior" or "likelihood";
    - `category`, the category of the dataline;
    - `priorProb/term`, the category prior probability if type="prior" / the term in string if type="likelihood";
    - `~/likelihoodProb`, None if type="prior" / the token (under spec-category) likelihood probability if type="likelihood";
- Users may define their own output path by changing **the second bracket part** of the training command;
- Commonly, the file created in training will be used for model test in prediction, defined by **the first bracket part** of the prediction command;

### Data Structures
- Raw data structure after JSON loading: a list contains multiple dictionaries, and each dictionary holds keys of doc, and text, each doc is considered as a data sample:
  - **Raw Input** >> List of dicts, \[{category_1:"XXX", text_1:"XX XX XXX""}, {category_2:"XXX", text_2:"XX XX XXX""}, ...]


- Rearranged training data structure: we assign each doc sample with and docID, this can be used as the key to take out the relevant data:
  - **Training/Test Data** >> Dict of nested-lists, {docID_1: \[docCategory_1, \[token_1_1, token_1_2, ...], docID_2:\[docCategory_2, \[token_2_1, token_2_2, ...]], ...}


- The model probability data structures for dara learned in training:
  - **Likelihoods Prob** >> Nested-dicts, {category_1: {token_1_1:99, token_1_2:88, ...}, category_2: {token_2_1:77, ...}, ...}
  - **Prior Prob** >> Hashtable, {category_1:0.999, category_2:0.1111, ...}


- The model predictions for each sample doc will be recorded as:
  - **Doc Prediction** >> Dict, {testDocId_1:"category", testDocId_2:"category", ...}

### Data Analysis
- The model prediction contains a method called self.modelAnalyze which will be call automatically to evaluate the model predictions;
- Analysis results needed will be printed to `STDOUT` channel:
  - Class-level: `true positive`, `false positive`, `false negative`, `true negative`;
  - Class-level: `precision`, `recall` and `F1 scores`;
  - Overall: `micro-averaged F1` & `macro-averaged F1` for the entire test set;
  
### Error Handling
- Any potential errors in given data or command processing will result in error messages (printed to `STDERR`) and running stop unexpectedly;


- `EmptyQueryError`: Input path(s) is/are invalid;
  - Invalid or empty path(s) input;
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.json');
  - Reminder: the indexed file input should have a path/filename ends with ".json";
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.tsv');
  - Reminder: the indexed file input should have a path/filename ends with ".tsv";
  - --> Error message to STDERR; Process Exits;


- `DetectionError`: Failed to detect input validation;
  - Satisfy the file format but cannot find the file within directory;
  - --> Error message to STDERR; Process Exits;


- `InputError`: Failed to input given data to the model; 
  - Cannot find the model file via input path;
  - --> Error message to STDERR; Process Exits;


- `ProcessingError`: Failed to process model training based on given data;
  - Failed to training model;
  - --> Error message to STDERR; Process Exits


- `OutputError`: Failed to output the model data; 
  - Failed to print data learned by model; 
  - --> Error message to STDERR; Process Exits;
  

## Model 02 - Rocchio Classifier

### Algorithms & Logics
#### Training
> The model takes in a JSON file containing training data and tokenizes the text using NLTK's word_tokenize function. The text is then filtered to remove stop words and punctuation marks, and the resulting tokens are stored in a hash table along with their corresponding category label.
> The ltc-scheme is applied in computing the in-doc token weights, each category is finally described as a centroid. ALl token idf values are stored for prediction use;
#### Prediction
> The prediction part initializes a set of class variables to be used across the methods. It has methods to tokenize, pruning, set the input parameters, filter the data, load the input data (test data and model), and calculate the ltc-weights based on idf values stored for each token. 
> Euclidean Distance is used to check the spacial distance b/w the test doc and category centroids in the vector space;

### Execution Commands
#### Training
* To run `rocchio_train.py` for training Rocchio models, using the command shown below:
 
  `python3 ./rocchio/rocchio_train.py [inputTrainingDataFilePath.json] [outputModelDataFilePath.tsv]`

  * The first bracket part is related to a `.json` file that contains all training data; 
  * The second bracket defines the model output file, which should be a `.tsv` file;

* A Formal sample command that could be used under the program directory is:
 
  `python3 ./rocchio/rocchio_train.py ./data/train.json ./rocchio_bbc_model.tsv`

#### Prediction
* To run `rocchio_prediction.py` for prediction on Rocchio models, using the command shown below:
 
  `python3 ./rocchio/rocchio_prediction.py [outputModelDataFilePath.tsv] [inputTestDataFilePath.json]`

  * The first bracket part is related to a `.tsv` file that contains all model data learned; 
  * The second bracket part is related to a `.json` file that contains all test data; 

* A Formal sample command that could be used under the program directory is:

  `python3 ./rocchio/rocchio_prediction.py ./rocchio_bbc_model.tsv ./data/test.json`

### Data Input
- By default, the program assumes the input training data files presented in the `/data` directory of the program package;
- And the original data should be stored in a file in the format of `.json`;
- Users may define their own input path (for training) by changing **the first bracket part** of the training command;
- Users may define their own input path (for test) by changing **the second bracket part** of the prediction command;

### Data Output
- Commonly, all the model data learned from model training will be stored in `.tsv` files in the program package;
  - Each TSV file contains data from an original JSON file, and it has **three** columns created: 
    - `type`, the type of the dataline, as "centroid" or "idf";
    - `category/term`, the category type if type="centroid" / the term in string if type="idf";
    - `categoryCentroid/termIDF`, category centroid represent in string (for each token and value) if type="centroid" / the token idf value if type="idf";
- Users may define their own output path by changing **the second bracket part** of the training command;
- Commonly, the file created in training will be used for model test in prediction, defined by **the first bracket part** of the prediction command;

### Data Structures
- Raw data structure after JSON loading: a list contains multiple dictionaries, and each dictionary holds keys of doc, and text, each doc is considered as a data sample:
  - **Raw Input** >> List of dicts, \[{category_1:"XXX", text_1:"XX XX XXX""}, {category_2:"XXX", text_2:"XX XX XXX""}, ...]


- Rearranged training data structure: we assign each doc sample with and docID, this can be used as the key to take out the relevant data:
  - **Training/Test Data** >> Dict of nested-lists, {docID_1: \[docCategory_1, \[token_1_1, token_1_2, ...], docID_2:\[docCategory_2, \[token_2_1, token_2_2, ...]], ...}


- The model probability data structures for dara learned in training:
  - **Category Centroid** >> Nested-dicts, {category_1: {token_1_1:tokenWeight_1_1, token_1_2:tokenWeight_1_2, ...}, category_2: {token_2_1:tokenWeight_2_1, ...}, ...}
  - **Token IDF** >> Hashtable, {token_1:tokenIDF_1, token_2:0.tokenIDF_2, ...}


- The model predictions for each sample doc will be recorded as:
  - **Doc Prediction** >> Dict, {testDocId_1:"category", testDocId_2:"category", ...}


- Distance recording and ranking data structures:
  - **Distance Recorder** >> Dict, {category_1:distToTestDocInInt_1, category_2:distToTestDocInInt_2, ...}
  - **Distance Ranker** >> MinHeap, \[(distToTestDocInInt_1, categoryCentroid_1), (distToTestDocInInt_2, categoryCentroid_2), ...]


### Data Analysis
- The model prediction contains a method called self.modelAnalyze which will be call automatically to evaluate the model predictions;
- Analysis results needed will be printed to `STDOUT` channel:
  - Class-level: `true positive`, `false positive`, `false negative`, `true negative`;
  - Class-level: `precision`, `recall` and `F1 scores`;
  - Overall: `micro-averaged F1` & `macro-averaged F1` for the entire test set;

### Error Handling
- `EmptyQueryError`: Input path(s) is/are invalid;
  - Invalid or empty path(s) input;
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.json');
  - Reminder: the indexed file input should have a path/filename ends with ".json";
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.tsv');
  - Reminder: the indexed file input should have a path/filename ends with ".tsv";
  - --> Error message to STDERR; Process Exits;


- `DetectionError`: Failed to detect input validation;
  - Satisfy the file format but cannot find the file within directory;
  - --> Error message to STDERR; Process Exits;


- `InputError`: Failed to input given data to the model; 
  - Cannot find the model file via input path;
  - --> Error message to STDERR; Process Exits;


- `ProcessingError`: Failed to process model training based on given data;
  - Failed to training model;
  - --> Error message to STDERR; Process Exits


- `OutputError`: Failed to output the model data; 
  - Failed to print data learned by model;
  - --> Error message to STDERR; Process Exits;


## Model 03 - k-Nearest Neighbors (kNN) Classifier

### Algorithms & Logics
#### Preparation
> The model takes in a JSON file containing training data and tokenizes the text using NLTK's word_tokenize function. The text is then filtered to remove stop words and punctuation marks, and the resulting tokens are stored in a hash table along with their corresponding doc label.
> The ltc-scheme is applied in computing the in-doc token weights, each doc is finally described as a vector. All token idf values are stored for prediction use;
#### Prediction
> The prediction part initializes a set of class variables to be used across the methods. It has methods to tokenize, pruning, set the input parameters, filter the data, load the input data (test data and model), and calculate the ltc-weights based on idf values stored for each token. 
> Euclidean Distance is used to check the spacial distance b/w the test doc and existed training doc vectors in the vector space;

### Execution Commands
#### Preparation
* To run `knn_create_vectors.py` for training kNN models, using the command shown below:

   `python3 ./knn/knn_create_vectors.py [inputTrainingDataFilePath.json] [outputModelDataFilePath.tsv]`

  * The first bracket part is related to a `.json` file that contains all training data; 
  * The second bracket defines the model output file, which should be a `.tsv` file;
 
* A Formal sample command that could be used under the program directory is:
  
  `python3 ./knn/knn_create_vectors.py ./data/train.json ./knn_bbc_vectors.tsv`

#### Prediction
* To run `knn_prediction.py` for prediction on kNN models, using the command shown below:
 
  `python3 ./knn/knn_prediction.py [outputModelDataFilePath.tsv] [inputTestDataFilePath.json] [hyperparameter:k-value]`

  * The first bracket part is related to a `.tsv` file that contains all model data learned; 
  * The second bracket part is related to a `.json` file that contains all test data; 
  * The third bracket part defines the hyperparameter (the k-value, determines how many neighbors will be considered) of the prediction model, which should be an `int` value;

* A Formal sample command that could be used under the program directory is:

  `python3 ./knn/knn_prediction.py ./knn_bbc_vectors.tsv ./data/test.json 11`

### Data Input
- By default, the program assumes the input training data files presented in the `/data` directory of the program package;
- And the original data should be stored in a file in the format of `.json`;
- Users may define their own input path (for training) by changing **the first bracket part** of the training command;
- Users may define their own input path (for test) by changing **the second bracket part** of the prediction command;
- Users may define their own hyperparameter (for test) by changing **the third bracket part** of the prediction command;

### Data Output
- Commonly, all the model data learned from model training will be stored in `.tsv` files in the program package;
  - Each TSV file contains data from an original JSON file, and it has **three** columns created: 
    - `type`, the type of the dataline, as "vector" or "idf";
    - `category/term`, the category type for doc if type="vector" / the term in string if type="idf";
    - `docVector/termIDF`, doc token values represent in string (for each token and value) if type="vector" / the token idf value if type="idf";
- Users may define their own output path by changing **the second bracket part** of the training command;
- Commonly, the file created in training will be used for model test in prediction, defined by **the first bracket part** of the prediction command;

### Data Structures
- Raw data structure after JSON loading: a list contains multiple dictionaries, and each dictionary holds keys of doc, and text, each doc is considered as a data sample:
  - **Raw Input** >> List of dicts, \[{category_1:"XXX", text_1:"XX XX XXX""}, {category_2:"XXX", text_2:"XX XX XXX""}, ...]


- Rearranged training data structure: we assign each doc sample with and docID, this can be used as the key to take out the relevant data:
  - **Training/Test Data** >> Dict of nested-lists, {docID_1: \[docCategory_1, \[token_1_1, token_1_2, ...], docID_2:\[docCategory_2, \[token_2_1, token_2_2, ...]], ...}


- The model probability data structures for dara learned in training:
  - **Doc Weights** >> Nested-dicts, {docID_1: {token_1_1:tokenWeight_1_1, token_1_2:tokenWeight_1_2, ...}, docID_2: {token_2_1:tokenWeight_2_1, ...}, ...}
  - **Token IDF** >> Hashtable, {token_1:tokenIDF_1, token_2:0.tokenIDF_2, ...}


- The model predictions for each sample doc will be recorded as:
  - **Doc Prediction** >> Dict, {testDocId_1:"category", testDocId_2:"category", ...}


- Distance recording and ranking data structures:
  - **Distance Recorder** >> Dict, {category_1:distToTestDocInInt_1, category_2:distToTestDocInInt_2, ...}
  - **Distance Ranker** >> MinHeap, \[(distToTestDocInInt_1, DocWeights_1), (distToTestDocInInt_2, DocWeights_2), ...]



### Data Analysis
- The model prediction contains a method called self.modelAnalyze which will be call automatically to evaluate the model predictions;
- Analysis results needed will be printed to `STDOUT` channel:
  - Class-level: `true positive (TP)`, `false positive (FP)`, `false negative (FN)`, `true negative (TN)`;
  - Class-level: `precision`, `recall` and `F1 scores`;
  - Overall: `micro-averaged F1` & `macro-averaged F1` for the entire test set;


### Error Handling
- `EmptyQueryError`: Input path(s) is/are invalid;
  - Invalid or empty path(s) input;
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.json');
  - Reminder: the indexed file input should have a path/filename ends with ".json";
  - --> Error message to STDERR; Process Exits;


- `FilePathError`: The input file path is invalid; (Reminder: should end with '.tsv');
  - Reminder: the indexed file input should have a path/filename ends with ".tsv";
  - --> Error message to STDERR; Process Exits;


- `DetectionError`: Failed to detect input validation;
  - Satisfy the file format but cannot find the file within directory;
  - --> Error message to STDERR; Process Exits;


- `InputError`: Failed to input given data to the model; 
  - Cannot find the model file via input path;
  - --> Error message to STDERR; Process Exits;


- `ProcessingError`: Failed to process model training based on given data;
  - Failed to training model;
  - --> Error message to STDERR; Process Exits


- `OutputError`: Failed to output the model data; 
  - Failed to print data learned by model;
  - --> Error message to STDERR; Process Exits;


