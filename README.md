
# **CMPUT 416/500 - Machine Learning Methods in Detecting SQL Injection Vulnerability**

| Team Member   | Contact             |
|---------------|---------------------|
| Eden Zhou     | zhou9@ualberta.ca   |
| Jingtong Yang | jyang9@ualberta.ca  |
| Yuzhou Li     | yuzhou5@ualberta.ca |


# Project Overview

> This project focuses on utilizing Machine Learning (ML) models to detect SQL Injection vulnerabilities effectively. We employ five different ML models, each trained on the same dataset, to identify potential SQL Injection risks in SQL semantics. These models include Logistic Regression, Naive Bayes, k-nearest Neighbora and Support Vector Machine. The system is designed to use either individual models or a combination of all five to enhance detection accuracy.

### Key Features
- **Multi-Models Detection**: 
  - Utilize a variety of ML models to detect SQL injection vulnerabilities;
  - Combine insights from models for a comprehensive vulnerability assessment;
  - Pretrained models reloaded for stable detection performance;
  
- **Easy-to-use Interfaces**: 
  - Interactive detector interface, with multiple functions supported;
  - A formal sample provided that presents the practical application of the comprehensive detector;

- **Research Values**:
  - Examine and compare the performance of ML models on the task of "SQL injection detection";
  - 

# Installation
- **Environment**: Please build a `Python 3.8+` environment correctly, with `pip` extension prepared;
  
- **Extensions**: Using the following command under the program directory to install dependent libraries to the environment automatically:

      $ pip install -r requirements.txt
  - For data processing: `matplotlib` and `numpy`;
  - For model learning: `nltk`, `scikit-learn`,`gensim`, `joblib` and `torch`;
  - For presentations: `tqdm`, `prettytable` and `flask`;


# How to Use
- **Detector**: 
  - Execute `detector_lite.py` to start, then follow the interactive instruction below to continue the session:

        $ python3 Proj/detector_lite.py
  
  - **Interactive Options**:
    - `h` or `help` - Displays help instructions;
    - `d` or `detect` - Checks risks in an SQL input using the selected model;
    - `s` or `scan` - Scans an SQL input with all models for a comprehensive report;
    - `d` or `file` - Scans a web log file with all models;
    - `c` or `change` - Selects a different pre-trained model for detection;
    - `h` or `build` - Rebuilds the model from scratch;
    - `e` or `exit` - Exits the program;


- **Formal Example**: 
  - Execute `app.py` to start a **web-app demo**:

        $ python3 Proj/app.py
  - **Detector Deployment**:
    1. Enter potential SQL injection semantics to try the deployed detector;
    2. Feedbacks will be generated regard the **risk level** of your inputs;
    3. Then a system decision made to *accept OR deny* your request (for safety consideration);


# Data Availability
## Data Input
- **Dataset**: 
  - The dataset used in this project is in txt filename ends with `-sqli` (e.g., burp-sqli.txt), which contains a series of SQL injection samples.
- **Labels**: Corresponding labels for the dataset are provided in txt file named with "-labels" (eg.burp-labels.txt) , which has same name as Dataset (eg.burp).
- Location: Both files are located in the /data directory of the project.
- [Format] ("): The dataset file contains SQL injection patterns, while the labels file contains binary classifications (1 for vulnerable, 0 for non-vulnerable).
  - Data Input and Organization: The class reads SQL queries and their corresponding labels from files, normalizes the text, and organizes them into structured feature vectors and labels.


## Data Preprocessing
- Class `Preprocessor` from `detector.py` preprocesses data before feeding into models for learning. A few processes taken:
  - **1. Tokenization**: 
    - It tokenizes each SQL query into individual words, standardizing the raw text data for processing;
    - vectorization using Doc2Vec, normalization using tokenization, and splitting into training and test sets, which transforms raw SQL data into a format that's ready for machine learning model training and evaluation..
  
  - **2. Normalization**: 
    - Optional Process;

  - **3. Vectorization**: 
      - Using the Doc2Vec model, it converts the tokenized SQL queries into numerical vector representations, making them understandable for machine learning models.
  - **4. Splitting**: The dataset is split into training and testing sets, a crucial step for evaluating the performance of the machine learning models on unseen data.


# Model Description
## Model Features
- **[Logistic Regression Model]("models/logReg.py")**
  - Purpose: Implements a Logistic Regression model for detecting SQL injection risks.
  - Features:
    - Utilizes cross-validation for optimizing model performance.
    - Hyperparameter tuning to find the optimal 'C' value (regularization strength).
    - Evaluates performance using metrics like Mean Squared Error (MSE), F1-score, and balanced accuracy.
  - Usage: The LogRegModel class provides methods for training, storing, reloading, and predicting, tailored for SQL injection vulnerability detection using the Logistic Regression algorithm.


- **[Naive Bayes (NBs) Model]("models/nb.py")**
  - Purpose: Implements a Naive Bayes classifier, specifically using the BernoulliNB variant, for detecting SQL injection vulnerabilities.
  - Features:
    - Conducts cross-validation to fine-tune model performance.
    - Hyperparameter tuning to find the optimal alpha (\(\alpha\)) value for smoothing.
    - Evaluates performance using metrics like Mean Squared Error (MSE), accuracy, and balanced accuracy.
  - Usage: The NBModel class is designed for training, storing, reloading, and making predictions, tailored to SQL injection vulnerability detection using the Naive Bayes algorithm.


- **[k-Nearest Neighbors (k-NN) Model]("models/knn.py")**
  - Purpose: Implements a k-Nearest Neighbor model for detecting SQL injection risks.
  - Features:
    - Cross-validation for model tuning.
    - Hyperparameter optimization to find the best k value.
    - Performance evaluation using F1-score and balanced accuracy.
  -  Usage: The KNNModel class provides methods for training, storing, reloading, and predicting using the k-Nearest Neighbor algorithm.


- **[Support Vector Machine (SVM) Model]("models/svm.py")**
  - Purpose: Implements a Support Vector Machine (SVM) model for detecting SQL injection risks.
  - Features:
    - Employs cross-validation to optimize model performance.
    - Hyperparameter tuning to identify the best 'C' value (regularization parameter).
    - Performance evaluation using metrics like Mean Squared Error (MSE), F1-score, and balanced accuracy.
  - Usage: The SVMModel class is designed for training, storing, reloading, and predicting, specifically for SQL injection vulnerability detection using the SVM algorithm.


## Model Learning
- The Classifier class (detector.py) trains various machine learning models on the preprocessed data. It supports both new training and using pre-trained models.
  - Initialization: It's set up with cross-validation settings, a preprocessor for data, a list of machine learning models, and evaluation metrics.
  - Classification Process: The class manages the training of models in 'NEW' mode or uses pre-trained models in 'PRE' mode. It iterates through each model, applying them to the dataset for training or prediction.
  - Integration with Preprocessor: Relies on preprocessed data (vectorized and split into training and testing sets) from the Preprocessor class for model training and testing.
  - Flexibility with Multiple Models: Capable of handling various machine learning models, allowing for flexibility and comparison of different algorithms.


# Error handling
- Model Selection Validation: The code ensures that the selected machine learning model is within a valid range (0-4). If an invalid model is chosen, the script notifies the user and halts execution, preventing any undefined behavior.
- Command-Line Argument Verification: The script checks for correct command-line arguments for MODE, SELECTION, and CV. If these are missing or incorrect, it defaults to preset values, allowing the program to continue running smoothly without abrupt termination.
- File Existence Check: When loading pre-trained model files, the script checks if these files exist. If a file is not found, it informs the user instead of causing a file-not-found error.

# Performance Comparisons
|                        | [Logistic Regression]() | [k-Nearest Neighbors]() | [Naive Bayes]() | [Support Vector Machine]() | 
|------------------------|-------------------------|-------------------------|-----------------|----------------------------|
| TP                     |                         |                         |                 |                            |                         
| FP                     |                         |                         |                 |                            |                         
| TN                     |                         |                         |                 |                            |
| FN                     |                         |                         |                 |                            |                         
| Accuracy               |                         |                         |                 |                            |                         
| F1_micro               |                         |                         |                 |                            |                         
| F1_macro               |                         |                         |                 |                            |                         
| Test Loss              |                         |                         |                 |                            |                         
| Optimal Hyperparameter |                         |                         |                 |                            |                         

