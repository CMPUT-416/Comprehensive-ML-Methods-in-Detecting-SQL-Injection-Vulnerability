import sys
from tqdm import tqdm
from preprocessor import Preprocessor
from models.knn import KNNModel
from models.nb import NBModel
from models.logReg import LogRegModel
from models.svm import SVMModel
from models.dt import DTModel
from models.gbdt import GBDTModel
from models.dnn import DeepNNModel
import nltk
nltk.download('punkt')


class Classifier:
    def __init__(self, cv: int, preprocessor, classifiers: list, evals: tuple):
        """
           Taking classifier initialized; Set parameters for the model learning process;
        :param
            - cv, int, the fold number for cross-validation;
            - preprocessor, Preprocessor, the data preprocessor used, contains datasets for training and prediction;
            - classifiers, list, contains all objects of models selected that will be used to process learning;
            - evals, tuple, contains all evaluation benchmarks selected that will be used for performance analysis;
        """
        # Classifier parameters initialized
        self.preprocessor = preprocessor
        self.cv: int = cv
        self.evals: tuple = evals
        self.classifiers: list = classifiers

    def classify(self):
        """
            This method facilitates each classification model selected to classify (.classify() is an automatic
        controller built-in each model that controls the whole learning process);
        """
        # Outputs indication information
        print("+" * 60)
        print("\t\t\t\t** MODEL LEARNING **")
        print("+" * 60 + '\n')
        print(f">> Training Settings"
              f"\n\t> Method of {self.cv}-fold Cross-validation"
              f"\n\t> Benchmarks of {self.evals}")
        print(f">> Modelling & Predictions")

        # Process each classification model by giving datasets, calling .classify() methods to start model learning
        for classifier in tqdm(self.classifiers):
            print('\n')
            classifier.classify(self.preprocessor.datasets_train, self.preprocessor.datasets_test, doTraining=True)

        # Outputs indication information
        print('\n' + "+" * 60)
        print("\t\t\t** MODEL PREDICTION ACCOMPLISHED **")
        print("+" * 60 + '\n\n')


def main(argv):
    """
        This is the main controller function for the whole model learning process. By executing this function, the whole
    learning task will be automatically reprocess, and regenerate all information needed: prediction outcomes,
    performance analysis data/diagrams, tuning/optimization reports, and pre-trained models; Highly recommend to use for
    the reproduction and replication process;
    """

    """ Dashboard """
    # Initialize model learning strategy
    CV = 3
    evals = ('neg_mean_squared_error', 'f1_micro', 'balanced_accuracy')
    try:
        CV = int(argv[1])
    except:
        sys.stderr.write(f"\n>> The fold num for the K-fold Cross-validation is set to be {CV};")
        #exit()

    # Initialize new models
    classifiers = [LogRegModel(cv=CV, cvEval=evals),
                    NBModel(cv=CV, cvEval=evals),
                    KNNModel(cv=CV, cvEval=evals),
                    SVMModel(cv=CV, cvEval=evals),
                    DTModel(cv=CV, cvEval=evals),
                    GBDTModel(cv=CV, cvEval=evals),
                    DeepNNModel(input_dim=100, hidden_dim=200, output_dim=2)]

    """ Preprocessing """
    # Input datasets and activate the data preprocessor
    P = Preprocessor(dirPath="data/")
    P.process()


    """ Modelling """
    # Input parameters, models and benchmarks that depends on learning design and activate the classifier
    C = Classifier(cv=CV, preprocessor=P, classifiers=classifiers, evals=evals)
    C.classify()


if __name__ == '__main__':
    # Start from a command line input
    main(sys.argv)