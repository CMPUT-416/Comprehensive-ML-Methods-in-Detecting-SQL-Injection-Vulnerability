import skops.io as sio
import numpy as np
from matplotlib import pyplot as plt
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, log_loss

class KNNModel:
    def __init__(self, cv: int, cvEval: tuple):
        # Training Settings:
        self.bestClassifier = None
        self.bestTrainingLoss = np.inf
        self.trainingLosses = []

        # Cross Validation Settings:
        self.cvEval: tuple = cvEval
        self.cv: int = cv
        self.cvErrors: list = []
        self.cvFValues: list = []
        self.cvBalAcc:list = []

        # Hyperparameter:
        self.bestK = 0
        self.hyperParams = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]

    def classify(self, datasets_train, datasets_test, doTraining=True):
        if doTraining:
            self._training(datasets_train=datasets_train)
            self._evaluate()
            self._store()
        self._predict(datasets_test=datasets_test, doTraining=doTraining)

    def _training(self, datasets_train: tuple):
        # Data Unpacking:
        X_train = datasets_train[0]
        y_train = np.ravel(datasets_train[1])

        # Cross-Validation Process:
        for hyperParam in self.hyperParams:
            classifier = KNeighborsClassifier(n_neighbors=hyperParam)
            classifier.fit(X_train, y_train)

            # Fitting Evaluation & Scoring:
            MSE = -cross_val_score(classifier, X_train, y_train,
                                   scoring=self.cvEval[0],
                                   cv=self.cv)
            F = cross_val_score(classifier, X_train, y_train,
                                       scoring=self.cvEval[1],
                                       cv=self.cv)
            balancedAccuracies = cross_val_score(classifier, X_train, y_train,
                                                 scoring=self.cvEval[2],
                                                 cv=self.cv)
            self.cvErrors.append(np.mean(MSE))
            self.cvFValues.append(np.mean(F))
            self.cvBalAcc.append(np.mean(balancedAccuracies))

        self.bestK = self.hyperParams[self.cvFValues.index(max(self.cvFValues))]
        self.bestClassifier = KNeighborsClassifier(n_neighbors=self.bestK)
        self.bestClassifier.fit(X_train, y_train)

    def _store(self):
        sio.dump(self.bestClassifier, 'srcs/knn.pkl')

    def _reload(self):
        self.bestClassifier = sio.load('srcs/knn.pkl', trusted=True)

    def _predict(self, datasets_test: tuple, doTraining: bool):
        # Data Unpacking:
        X_test = datasets_test[0]
        y_test = np.ravel(datasets_test[1])

        # Classifier Testing:
        y_test_hat = self.bestClassifier.predict(X_test)
        y_test_proba = self.bestClassifier.predict_proba(X_test)  # Assuming predict_proba is available for kNN

        test_accuracy = accuracy_score(y_test, y_test_hat)
        test_f1_macro = f1_score(y_test, y_test_hat, average='macro')
        test_f1_micro = f1_score(y_test, y_test_hat, average='micro')
        tn, fp, fn, tp = confusion_matrix(y_test, y_test_hat).ravel()

        # Calculating log loss as test loss
        test_loss = log_loss(y_test, y_test_proba)

        results = (f"\n> Model of K-Nearest Neighbors (kNN):"
                f"\n\t* Optimal HyperParameter --> k={self.bestK} (neighbors)"
                f"\n\t* Test Accuracy --> Accuracy={test_accuracy}"
                f"\n\t* Test F-score (Macro) --> F1 (Macro)={test_f1_macro}"
                f"\n\t* Test F-score (Micro) --> F1 (Micro)={test_f1_micro}"
                f"\n\t* True Positives (TP) --> TP={tp}"
                f"\n\t* False Positives (FP) --> FP={fp}"
                f"\n\t* True Negatives (TN) --> TN={tn}"
                f"\n\t* False Negatives (FN) --> FN={fn}"
                f"\n\t* Test Loss --> Loss={test_loss:.4f}\n")
        
        if doTraining:
            filename = "eval/KNNModel_results_training.txt"
            #print("it does train")
            print(results)
        else:
            filename = "eval/KNNModel_results_pretrained.txt"

        with open(filename, "w") as file:
            file.write(results)

        print(f"Results saved to {filename}")



    def simpleDetect(self, sql):
        return self.bestClassifier.predict(sql.reshape(1, -1))

    def _evaluate(self):
        plt.figure()
        plt.plot(self.hyperParams, self.cvBalAcc, color='red')
        plt.xlabel('k-value (HyperParam, #neighbors)')
        plt.ylabel('Mean of Balanced Accuracy (in Cross Validation)')
        plt.title('k-value (HyperParam) vs. Mean of Balanced Accuracy')
        plt.savefig("eval/KNNModel_1_hyperParams_vs_balanced_accuracy.png")

        plt.figure()
        plt.plot(self.hyperParams, self.cvErrors, color='green')
        plt.xlabel('k-value (HyperParam, #neighbors)')
        plt.ylabel('Average MSE (in Cross Validation)')
        plt.title('k-value (HyperParam) vs. Average MSE')
        plt.savefig("eval/KNNModel_2_hyperParams_vs_cvAvgErrors.png")

        plt.figure()
        plt.plot(self.hyperParams, self.cvFValues, color='orange')
        plt.xlabel('k-value (HyperParam, #neighbors)')
        plt.ylabel('Mean of  F1-values (in Cross Validation)')
        plt.title('k-Value (HyperParam) vs. Mean of F1-Values')
        plt.savefig("eval/KNNModel_3_hyperParams_vs_cvFValues.png")

