import joblib
import numpy as np
from matplotlib import pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score

class DecisionTreeModel:
    def __init__(self, cv: int, cvEval: tuple):
        self.bestClassifier = None
        self.bestDepth = None
        self.cvEval: tuple = cvEval
        self.cv: int = cv
        self.cvErrors: list = []
        self.cvFValues: list = []
        self.cvAccuracies: list = []
        self.depths = list(range(1, 11))  

    def classify(self, datasets_train, datasets_test, doTraining=True):
        if doTraining:
            self._training(datasets_train=datasets_train)
            self._evaluate()
            self._store()
        self._predict(datasets_test=datasets_test, doTraining=doTraining)

    def _training(self, datasets_train: tuple):
        X_train, y_train = datasets_train

        for depth in self.depths:
            classifier = DecisionTreeClassifier(max_depth=depth)
            classifier.fit(X_train, y_train)

            # Cross-Validation
            cv_accuracy = cross_val_score(classifier, X_train, y_train, scoring='accuracy', cv=self.cv)
            cv_f1 = cross_val_score(classifier, X_train, y_train, scoring='f1_macro', cv=self.cv)

            self.cvAccuracies.append(np.mean(cv_accuracy))
            self.cvFValues.append(np.mean(cv_f1))

        # Select the best depth based on F1 Score
        self.bestDepth = self.depths[self.cvFValues.index(max(self.cvFValues))]
        self.bestClassifier = DecisionTreeClassifier(max_depth=self.bestDepth)
        self.bestClassifier.fit(X_train, y_train)

    def _store(self):
        joblib.dump(self.bestClassifier, 'srcs/dt.pkl')

    def _reload(self):
        self.bestClassifier = joblib.load('srcs/dt.pkl')

    def _predict(self, datasets_test: tuple, doTraining: bool):
        X_test, y_test = datasets_test
        y_pred = self.bestClassifier.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_pred)
        test_f1 = f1_score(y_test, y_pred, average='macro')

        if doTraining:
            print(f"\n\t> Model of Decision Tree:"
                  f"\n\t\t*   Optimal HyperParameter"
                  f"\n\t\t        --> depth={self.bestDepth}"
                  f"\n\t\t*   Test F-score "
                  f"\n\t\t        --> F1={test_f1}")
        else:
            print(f"\n\t> Model of Decision Tree - Pre-trained:"
                  f"\n\t\t*   Test F-score "
                  f"\n\t\t        --> F1={test_f1}")

    def _evaluate(self):
        plt.figure()
        plt.plot(self.depths, self.cvAccuracies, color='red')
        plt.xlabel('Tree Depth (Hyperparameter)')
        plt.ylabel('Mean of Accuracy (in Cross Validation)')
        plt.title('Tree Depth vs. Mean of Accuracy')
        plt.savefig("eval/DecisionTreeModel_1_depth_vs_accuracy.png")

        plt.figure()
        plt.plot(self.depths, self.cvAccuracies, color='green')
        plt.xlabel('Tree Depth (Hyperparameter)')
        plt.ylabel('Mean of Accuracy (in Cross Validation)')
        plt.title('Tree Depth vs. Mean of Accuracy')
        plt.savefig("eval/DecisionTreeModel_2_depth_vs_accuracy.png")

        plt.figure()
        plt.plot(self.depths, self.cvFValues, color='orange')
        plt.xlabel('Tree Depth (Hyperparameter)')
        plt.ylabel('Mean of F1-Values (in Cross Validation)')
        plt.title('Tree Depth vs. Mean of F1-Values')
        plt.savefig("eval/DecisionTreeModel_3_depth_vs_f1.png")