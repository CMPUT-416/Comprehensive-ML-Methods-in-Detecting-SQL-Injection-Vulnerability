import joblib
import numpy as np

from matplotlib import pyplot as plt
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score


class GBDTModel:
    def __init__(self, cv: int, cvEval: tuple):
        """
           Taking a Gradient Boost Decision Tree model initialized; Set parameters for the model learning process;
        :param
            - cv, int, the fold number for cross-validation;
            - cvEval, tuple, contains all evaluation benchmarks selected that will be used for performance analysis;
        """
        # Training Records
        self.bestClassifier = None
        self.bestDepth = None
        self.bestN = None

        # Cross-validation Settings
        self.cvEval: tuple = cvEval
        self.cv: int = cv
        self.cvErrors: list = []
        self.cvFValues: list = []
        self.cvAccuracies: list = []

        # Hyperparameter Settings
        self.bests: dict = {}
        self.depths = list(range(2, 8))
        self.N = [50, 100, 300, 500, 1000]


    def classify(self, datasets_train, datasets_test, doTraining=True):
        """
            This is a controller method that will automatically execute the model learning process. The parameter will
        determine the task of "training + prediction" (redoing the whole process) or "only prediction" (after reloading);
        :param
            - datasets_train, tuple, training datasets for the model;
            - datasets_test, tuple, testing datasets for the model;
            - doTraining, bool, whether to perform a training phase;
        """
        if doTraining:
            # Take the training process
            self._training(datasets_train=datasets_train)
            self._evaluate()
            self._store()
        # Take the prediction process
        self._predict(datasets_test=datasets_test, doTraining=doTraining)

    def _training(self, datasets_train: tuple):
        """
            This method is used to train the Gradient Boost Decision Tree model by taking cross-validations for each selection
        of the hyperparameters; The method will figure out the optimal choice by checking the F1-score;
        :param
            - datasets_train, tuple, training datasets for the model;
        """
        print(">> WARNING: This model may take minute to train, try using pre-trained version instead of retraining;")
        # Unpacking X (features), y (labels) from the training dataset
        X_train, y_train = datasets_train

        # Loop over each selection of the first hyperparameter
        for n in self.N:
            errors = []
            fvalues = []
            acces = []
            # Loop over each selection of the second hyperparameter to process the learning
            for depth in self.depths:
                # Taking cross-Validations and acquiring model performance indications based on MSE, F-score and accuracy
                MSE = -cross_val_score(GradientBoostingClassifier(n_estimators=n, learning_rate=0.1, max_depth=depth),
                                       X=X_train,
                                       y=y_train,
                                       scoring=self.cvEval[0],
                                       cv=self.cv,
                                       n_jobs=-1)
                cv_f1 = cross_val_score(GradientBoostingClassifier(n_estimators=n, learning_rate=0.1, max_depth=depth),
                                        X=X_train,
                                        y=y_train,
                                        scoring=self.cvEval[1],
                                        cv=self.cv,
                                        n_jobs=-1)
                balancedAccuracies = cross_val_score(GradientBoostingClassifier(n_estimators=n, learning_rate=0.1, max_depth=depth),
                                                     X=X_train,
                                                     y=y_train,
                                                     scoring=self.cvEval[2],
                                                     cv=self.cv,
                                                     n_jobs=-1)
                # Record the performance for a specific second hyperparameter, taking the mean performance over folds of cross-validation
                errors.append(np.mean(MSE))
                fvalues.append(np.mean(cv_f1))
                acces.append(np.mean(balancedAccuracies))
                # Record the best selection in this round, using the f1-value as the keys and the choice of hyperparameters as the values;
                self.bests[max(fvalues)] = [n, self.depths[fvalues.index(max(fvalues))]]

            # Record the performance of hyperparameters
            self.cvErrors.append(errors)
            self.cvFValues.append(fvalues)
            self.cvAccuracies.append(acces)

        # Find the best hyperparameter choices. Apply the best hyperparameters to build a formal classifier
        self.bestN, self.bestDepth = self.bests.get(max(self.bests.keys()))
        self.bestClassifier = GradientBoostingClassifier(n_estimators=self.bestN, learning_rate=0.3, max_depth=self.bestDepth)
        self.bestClassifier.fit(X_train, y_train)

    def _store(self):
        """
            This method is used to store the best classifier model into a local file;
        """
        # Save the best sample model with the optimal hyperparameter to the directory `Proj/srcs` with name `dt.pkl`
        joblib.dump(self.bestClassifier, 'srcs/gbdt.pkl')

    def _reload(self):
        """
            This method is used to reload the pre-trained optimal classifier model from a local file;
        """
        # Reload the best sample model with the optimal hyperparameter from the directory `Proj/srcs` with name `dt.pkl`
        self.bestClassifier = joblib.load('srcs/gbdt.pkl')

    def _predict(self, datasets_test: tuple, doTraining: bool):
        """
            This method is used to predict the testing datasets and evaluate its performance;
        :param
            - datasets_test, tuple, testing datasets for the model;
            - doTraining, bool, whether the model has been trained before prediction, for different message indications;
        """
        # Unpack datasets and then feed into the model
        X_test, y_test = datasets_test

        # Compare predictions with the ground truth values to compute the accuracy and macro-F1-score
        y_pred = self.bestClassifier.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_pred)
        test_f1 = f1_score(y_test, y_pred, average='macro')

        # Outputs indication information
        if doTraining:
            print(f"\n\t> Model of Gradient Boost Decision Tree:"
                  f"\n\t\t*   Optimal HyperParameter"
                  f"\n\t\t        --> depth={self.bestDepth}"
                  f"\n\t\t        --> n={self.bestN}"
                  f"\n\t\t*   Test F-score "
                  f"\n\t\t        --> F1={test_f1}")
        else:
            print(f"\n\t> Model of Gradient Boost Decision Tree - Pre-trained:"
                  f"\n\t\t*   Test F-score "
                  f"\n\t\t        --> F1={test_f1}")

    def simpleDetect(self, sql):
        """
            A simple version for prediction designed for our quick-check detector; Performs a prediction for a
        single-line input;
        :param
            - sql, numpy.ndarray, the input data to predict;
        :return
            - predictions, numpy.ndarray, the prediction result for the input of SQL semantics.
        """
        # Resize the input data and ask the model to make predictions
        return self.bestClassifier.predict(sql.reshape(1, -1))

    def _evaluate(self):
        """
            Inner method used to evaluate the performance of the model by plotting analysis diagrams of hyperparameter
        versus mean accuracy, average mean squared error, and F1-Values;
        """
        # There are two hyperparameters, so three diagrams will be created for each choice of the first hyperparameter
        index = 0
        while index < len(self.cvAccuracies):
            # Loop over the first hyperparameter of n value
            n = self.N[index]

            # Create and save an analysis diagram about "Hyperparameter vs. Balanced Accuracy" for `n` to `Proj/eval`
            plt.figure()
            plt.plot(self.depths, self.cvAccuracies[index], color='red')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Mean of Balanced Accuracy (in Cross Validation)')
            plt.title(f'Tree Depth vs. Mean of Accuracy (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_1_{n}_depth_vs_accuracy.png")

            # Create and save an analysis diagram about "Hyperparameter vs. Mean Squared Error" for `n` to `Proj/eval`
            plt.figure()
            plt.plot(self.depths, self.cvErrors[index], color='green')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Average MSE (in Cross Validation)')
            plt.title(f'Tree Depth vs. Average MSE (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_2_{n}_depth_vs_cvAvgErrors.png")

            # Create and save an analysis diagram about "Hyperparameter vs. F1-values" for `n` to `Proj/eval`
            plt.figure()
            plt.plot(self.depths, self.cvFValues[index], color='orange')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Mean of F1-Values (in Cross Validation)')
            plt.title(f'Tree Depth vs. Mean of F1-Values (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_3_{n}_depth_vs_f1.png")

            index += 1