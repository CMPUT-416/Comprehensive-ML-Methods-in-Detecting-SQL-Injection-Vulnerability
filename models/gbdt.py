import joblib
import numpy as np

from matplotlib import pyplot as plt
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score
from sklearn.metrics import confusion_matrix, log_loss

class GBDTModel:
    def __init__(self, cv: int, cvEval: tuple):
        self.bestClassifier = None
        self.bestDepth = None
        self.bestN = None

        self.cvEval: tuple = cvEval
        self.cv: int = cv

        self.cvErrors: list = []
        self.cvFValues: list = []
        self.cvAccuracies: list = []
        self.bests: dict = {}

        # self.depths = list(range(2, 8))
        self.depths = list(range(2, 6))
        # self.N = [100]      # [50, 100, 300, 500, 1000]
        self.N = [10,20,30]   #for speed up, 
                              #it shows better performance when start as 50,  - 11/27


    def classify(self, datasets_train, datasets_test, doTraining=True):
        if doTraining:
            self._training(datasets_train=datasets_train)
            self._evaluate()
            self._store()
        self._predict(datasets_test=datasets_test, doTraining=doTraining)

    def _training(self, datasets_train: tuple):
        print(">> WARNING: This model may take minute to train, try using pre-trained version instead of retraining;")
        X_train, y_train = datasets_train
        for n in self.N:
            errors = []
            fvalues = []
            acces = []
            for depth in self.depths:
                classifier = GradientBoostingClassifier(n_estimators=n, learning_rate=0.3, max_depth=depth)
                classifier.fit(X_train, y_train)

                # Cross-Validation
                MSE = -cross_val_score(classifier, X_train, y_train,
                                       scoring=self.cvEval[0],
                                       cv=self.cv)
                cv_f1 = cross_val_score(classifier, X_train, y_train,
                                        scoring=self.cvEval[1],
                                        cv=self.cv)
                balancedAccuracies = cross_val_score(classifier, X_train, y_train,
                                                     scoring=self.cvEval[2],
                                                     cv=self.cv)
                errors.append(np.mean(MSE))
                fvalues.append(np.mean(cv_f1))
                acces.append(np.mean(balancedAccuracies))

                self.bests[max(fvalues)] = [n, self.depths[fvalues.index(max(fvalues))]]

            self.cvErrors.append(errors)
            self.cvFValues.append(fvalues)
            self.cvAccuracies.append(acces)

        # Select the best depth based on F1 Score
        self.bestN, self.bestDepth = self.bests.get(max(self.bests.keys()))
        self.bestClassifier = GradientBoostingClassifier(n_estimators=self.bestN, learning_rate=0.3, max_depth=self.bestDepth)
        self.bestClassifier.fit(X_train, y_train)

    def _store(self):
        joblib.dump(self.bestClassifier, 'srcs/gbdt.pkl')

    def _reload(self):
        self.bestClassifier = joblib.load('srcs/gbdt.pkl')

    def simpleDetect(self, sql):
        return self.bestClassifier.predict(sql.reshape(1, -1))

    def _predict(self, datasets_test: tuple, doTraining: bool):
        X_test, y_test = datasets_test
        y_pred = self.bestClassifier.predict(X_test)
        y_pred_proba = self.bestClassifier.predict_proba(X_test)  # For log loss

        test_accuracy = accuracy_score(y_test, y_pred)
        test_f1_macro = f1_score(y_test, y_pred, average='macro')
        test_f1_micro = f1_score(y_test, y_pred, average='micro')
        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

        # Calculating log loss as test loss
        test_loss = log_loss(y_test, y_pred_proba)

        results = (f"\n> Model of Gradient Boost Decision Tree:"
                f"\n\t* Optimal HyperParameter --> depth={self.bestDepth}, n={self.bestN}"
                f"\n\t* Test Accuracy --> Accuracy={test_accuracy}"
                f"\n\t* Test F-score (Macro) --> F1 (Macro)={test_f1_macro}"
                f"\n\t* Test F-score (Micro) --> F1 (Micro)={test_f1_micro}"
                f"\n\t* True Positives (TP) --> TP={tp}"
                f"\n\t* False Positives (FP) --> FP={fp}"
                f"\n\t* True Negatives (TN) --> TN={tn}"
                f"\n\t* False Negatives (FN) --> FN={fn}"
                f"\n\t* Test Loss --> Loss={test_loss:.4f}\n")

        if doTraining:
            filename = "eval/GBDTModel_results_training.txt"
            print(results)
        else:
            filename = "eval/GBDTModel_results_pretrained.txt"

        with open(filename, "w") as file:
            file.write(results)

        
        print(f"Results saved to {filename}")




    def _evaluate(self):
        index = 0
        while index < len(self.cvAccuracies):
            n = self.N[index]

            plt.figure()
            plt.plot(self.depths, self.cvAccuracies[index], color='red')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Mean of Balanced Accuracy (in Cross Validation)')
            plt.title(f'Tree Depth vs. Mean of Accuracy (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_1_{n}_depth_vs_accuracy.png")

            plt.figure()
            plt.plot(self.depths, self.cvErrors[index], color='green')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Average MSE (in Cross Validation)')
            plt.title('Tree Depth vs. Average MSE (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_2_{n}_depth_vs_cvAvgErrors.png")

            plt.figure()
            plt.plot(self.depths, self.cvFValues[index], color='orange')
            plt.xlabel('Tree Depth (Hyperparameter)')
            plt.ylabel('Mean of F1-Values (in Cross Validation)')
            plt.title('Tree Depth vs. Mean of F1-Values (for n={n})')
            plt.savefig(f"eval/GradientBoostDecisionTreeModel_3_{n}_depth_vs_f1.png")

            index += 1